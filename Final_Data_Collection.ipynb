{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXAees01I9GZ"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/CSE_497/Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2N4yLAVI9Ot"
      },
      "outputs": [],
      "source": [
        "import pandas as  pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping the datasets-\n",
        "\n",
        "The Kagle_Abstract_DS.zip can be downloaded from: https://www.kaggle.com/datasets/spsayakpaul/arxiv-paper-abstracts\n",
        "\n",
        "\n",
        "The Research_Summarization.zip can be downloaded from: https://cs.stanford.edu/~myasu/projects/scisumm_net/"
      ],
      "metadata": {
        "id": "BzecxtIe8mQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUvgLUkSL_ky"
      },
      "outputs": [],
      "source": [
        "!unzip Kaggle_Abstract_DS.zip\n",
        "!unzip Research_Summarization.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will combine our datasets in a single dataframe"
      ],
      "metadata": {
        "id": "D9TE0syl8RZJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI4DT02vbdoT"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns=['problem', 'approach'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93SjWjlkOsaq"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('arxiv_data.csv')\n",
        "df1.drop(columns=['terms'], inplace=True)\n",
        "df1.rename(columns={'titles': 'problem', 'summaries': 'approach'}, inplace=True)\n",
        "# ignoring short summaries/abstracts in an attempt that the model learns to generate detailed approaches\n",
        "df1.drop(index=df1[df1['approach'].str.len() < 500].index, inplace=True)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ScisummNet dataset has individual papers within separate directories. So, we need to iterate over them and collate the data."
      ],
      "metadata": {
        "id": "B1ga-vAA9Z8k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20zip1ZhswiD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "reg = re.compile(r'[A-Z][0-9]{2}-[0-9]{4}')\n",
        "i = 0\n",
        "\n",
        "df4 = pd.DataFrame(columns=['problem', 'approach'])\n",
        "base = '/content/drive/MyDrive/CSE_497/Final/Data/top1000_complete'\n",
        "for dir in os.listdir(base):\n",
        "  file_name = os.path.join(base, dir, \"summary\", dir + \".gold.txt\")\n",
        "  with open(file_name, 'r') as f:\n",
        "    data = f.readlines()\n",
        "    df4.loc[i] = [data[0], \"\\n\".join(data[1:])]\n",
        "    i += 1\n",
        "df4.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving in csv format such that it is easier to access later\n",
        "df4.to_csv(\"scisumnett_data.csv\")"
      ],
      "metadata": {
        "id": "znQn4veH88bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.read_csv(\"scisumnett_data.csv\")\n",
        "df4.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "J03drwlJ89uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the CSV file generated by GPT 4.5\n",
        "df6 = pd.read_csv(\"large_research_dataset.csv\")\n",
        "df6.rename(columns={'Research Problem': 'problem', 'Approach': 'approach'}, inplace=True)\n",
        "df6.head()"
      ],
      "metadata": {
        "id": "fP-Iz2qD2ieJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.reset_index(drop=True)\n",
        "df4 = df4.reset_index(drop=True)\n",
        "df6 = df6.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "kDtti6wdrKfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modifying the titles and summaries to conform to the project requirements"
      ],
      "metadata": {
        "id": "kKJJvUhLBkhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefixes = [\"Provide an approach for the following research problem: \",\n",
        "            \"Suggest a method to solve the following research challenge: \",\n",
        "            \"Devise a strategy to tackle the research problem: \",\n",
        "            \"How would you address the following research question? \",\n",
        "            \"What approach would you take for the following research task? \",\n",
        "            \"Propose a solution to the following research objective: \",\n",
        "            \"Explain how to work on the following research problem: \",\n",
        "            \"Generate a potential methodology for: \",\n",
        "            \"Design a research plan to address the problem: \",\n",
        "            \"What are possible steps to address the following issue? \"]\n",
        "\n",
        "approach_prefix = [\"An effective approach would be to:\",\n",
        "                   \"The proposed method involves the following steps:\",\n",
        "                   \"To address this problem, one could:\",\n",
        "                   \"The solution can be structured as follows:\",\n",
        "                   \"A suitable approach might involve:\",\n",
        "                   \"The following approch is based on a research paper:\",\n",
        "                   \"To solve the problem, you can follow an approach as adopted in the following:\"]\n",
        "\n",
        "index = 0\n",
        "def apply_prefixes(pre_list, text):\n",
        "  global index\n",
        "  index = (index + 1)%len(pre_list)\n",
        "  return pre_list[index] + str(text)\n",
        "\n",
        "df1['problem'] = df1['problem'].apply(lambda x: apply_prefixes(prefixes, x))\n",
        "\n",
        "index = 0\n",
        "df1['approach'] = df1['approach'].apply(lambda x: apply_prefixes(approach_prefix, x))\n",
        "\n",
        "index = 0\n",
        "df4['problem'] = df4['problem'].apply(lambda x: apply_prefixes(prefixes, x))\n",
        "\n",
        "index = 0\n",
        "df4['approach'] = df4['approach'].apply(lambda x: apply_prefixes(approach_prefix, x))\n",
        "\n",
        "index = 0\n",
        "df6['problem'] = df6['problem'].apply(lambda x: apply_prefixes(prefixes, x))"
      ],
      "metadata": {
        "id": "BR_zRLTcK4wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the final dataset"
      ],
      "metadata": {
        "id": "V3wL6o6MBhZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df, df1, df4, df6])\n",
        "df.to_csv(\"final_raw_data.csv\")"
      ],
      "metadata": {
        "id": "CQ6XV-7_K4tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WO2X2iZZBbt_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}